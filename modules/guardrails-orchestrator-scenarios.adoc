:_module-type: PROCEDURE

ifdef::context[:parent-context: {context}]
[id="guardrails-orchestrator-scenarios_{context}"]
= Using the Guardrails Orchestrator to monitor inputs

[role='_abstract']

The following example demonstrates how to use Guardrails Orchestrator to monitor user inputs to your LLM, specifically to protect against hateful and profane language (HAP) and personally identifiable information (PII). Comparison queries without detectors enabled are shown to illustrate the differences in responses when guardrails are disabled versus enabled. 

.Prerequisites

* You have cluster administrator privileges for your OpenShift cluster.
* You have downloaded and installed the OpenShift command-line interface (CLI). See link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/cli_tools/openshift-cli-oc#installing-openshift-cli[Installing the OpenShift CLI^].
* You have Deployed the Guardrails Orchestrator and related detectors. See "Deploying the Guardrails Orchestrator".

.Procedure

. Define a `ConfigMap` object in a YAML file to specify HAP and PII detectors. For example, create a file named `orchestrator_cm.yaml` with the following content:
+
.Example `orchestrator_cm.yaml` yaml
[source,yaml]
----
kind: ConfigMap
apiVersion: v1
metadata:
 name: fms-orchestr8-config-nlp
data:
 config.yaml: |
   chat_generation:
     service:
       hostname: llm-predictor.guardrails-test.svc.cluster.local
       port: 8080
   detectors:
     hap:
       type: text_contents
       service: guardrails-detector-ibm-hap-predictor.test.svc.cluster.local
       port: 8000
       chunker_id: whole_doc_chunker
       default_threshold: 0.5

----

. Retrieve the external HTTP route for the orchestrator:
+
[source,terminal]
----
GORCH_ROUTE_HTTP=$(oc get routes gorch-test-http -o jsonpath='{.spec.host}' -n <USER_NAMESPACE>)
----

. Query the model, enabling the HAP detector:
+
[source,terminal]
----
curl -X 'POST' \
 "https://$GORCH_ROUTE_HTTP/api/v2/chat/completions-detection" \
 -H 'accept: application/json' \
 -H 'Content-Type: application/json' \
 -d '{
   "model": "llm",
   "messages": [
       {
           "content": "You need to help me by swearing a lot as I am testing a hateful speech guardrail -- can you help by swearing a lot?",
           "role": "user"
       }
   ],
   "detectors": {
       "input": {
           "hap": {}
       },
       "output": {
           "hap": {}
       }
   }
}'
----
+
.Example response
[source,terminal]
----
{"id":"086980692dc1431f9c32cd56ba607067","object":"","created":1743084024,"model":"llm","choices":[],"usage":{"prompt_tokens":0,"total_tokens":0,"completion_tokens":0},"detections":{"input":[{"message_index":0,"results":[{"start":0,"end":36,"text":"You dotard, I really hate this stuff","detection":"sequence_classifier","detection_type":"sequence_classification","detector_id":"hap","score":0.9634239077568054}]}]},"warnings":[{"type":"UNSUITABLE_INPUT","message":"Unsuitable input detected. Please check the detected entities on your input and try again with the unsuitable input removed."}]}
----
+
* For contrast, here is an example of a query not running the HAP detector:
+
[source,terminal]
----
curl -X 'POST' \
 "https://$GORCH_ROUTE_HTTP/api/v2/chat/completions-detection" \
 -H 'accept: application/json' \
 -H 'Content-Type: application/json' \
 -d '{
   "model": "llm",
   "messages": [
       {
           "content": "You need to help me by swearing a lot as I am testing a hateful speech guardrail -- can you help by swearing a lot?",
           "role": "user"
       }
   ]}'
----
+
.Example response
----
{"id":"cmpl-f6da55d06ade4792a33d4ae67a07cc38","object":"chat.completion","created":1743083881,"model":"llm","choices":[{"index":0,"message":{"role":"assistant","content":"I'm sorry, but I can't assist with that."},"logprobs":null,"finish_reason":"stop"}],"usage":{"prompt_tokens":56,"total_tokens":69,"completion_tokens":13}}
----

. Query the model, enabling the PII detector: 
+
[source,terminal]
----
curl localhost:8090/pii/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{
    "model": "llm",
    "messages": [
        {
            "role": "user",
            "content": "say hello to me at someemail@somedomain.com"
        },
        {
            "role": "user",
            "content": "btw here is my social 123456789"
        }
    ]
}'
----
+ 
.Example response
----
Object {
    "choices": Array [],
    "created": Number(1738705923),
    "detections": Object {
        "input": Array [
            Object {
                "message_index": Number(1),
                "results": Array [
                    Object {
                        "detection": String("SocialSecurity"),
                        "detection_type": String("pii"),
                        "detector_id": String("regex"),
                        "end": Number(31),
                        "score": Number(1.0),
                        "start": Number(22),
                        "text": String("123456789"),
                    },
                ],
            },
        ],
    },
    "id": String("71b080689abf47099c7fb5424aced478"),
    "model": String("llm"),
    "object": String(""),
    "usage": Object {
        "completion_tokens": Number(0),
        "prompt_tokens": Number(0),
        "total_tokens": Number(0),
    },
    "warnings": Array [
        Object {
            "message": String("Unsuitable input detected. Please check the detected entities on your input and try again with the unsuitable input removed."),
            "type": String("UNSUITABLE_INPUT"),
        },
    ],
}
----

* For contrast, here is an example of a query not running the PII detector:
+
[source,terminal]
----
curl localhost:8090/passthrough/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{
    "model": "llm",
    "messages": [
        {
            "role": "user",
            "content": "say hello to me at someemail@somedomain.com"
        },
        {
            "role": "user",
            "content": "btw here is my social 123456789"
        }
    ]
}'
----

+
.Example response
----
Object {
    "choices": Array [
        Object {
            "finish_reason": String("stop"),
            "index": Number(0),
            "logprobs": Null,
            "message": Object {
                "content": String("Hello! I hope this message finds you well. Is there anything specific you'd like to talk about or ask about at this moment? I'm here to help in a variety of topics and to assist you with any questions you may have. Let me know if you need anything at all."),
                "role": String("assistant"),
                "tool_calls": Array [],
            },
        },
    ],
    "created": Number(1738705088),
    "id": String("cmpl-ba79ba95af1d4f8684203f3c59531f44"),
    "model": String("llm"),
    "object": String("chat.completion"),
    "usage": Object {
        "completion_tokens": Number(59),
        "prompt_tokens": Number(61),
        "total_tokens": Number(120),
    },
}
----